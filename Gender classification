# -*- coding: utf-8 -*-
"""
Created on Fri Apr  3 23:42:19 2020

@author: Salman
"""
#1)This code is intended to run on google colab as we can use GPU out there to train our model faster.

#2)Convolutional Neural Networks (CNNs) are designed to operate over the raw pixel intensities 
#of images and learn discriminating filters that can be used to classify images with high accuracy.
#The model that i have implemented is a smaller variant of VGGNet 
#VGGNet-like models share two common characteristics:
#Only 3×3 convolutions are used
#Convolution layers are stacked on top of each other deeper in the network architecture prior to 
#applying a destructive pooling operation

from google.colab import drive
drive.mount('/content/drive')


from keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential
from keras.layers import Conv2D,MaxPooling2D
from keras.layers import Activation,Dropout,Flatten,Dense
from keras.layers.normalization import BatchNormalization
from keras import backend as K
import numpy as np
from keras.preprocessing import image

#######################################Generate_data###############################################################

img_width,img_height=150,150
train_data_dir='/content/drive/My Drive/Colab Notebooks/train'
validation_data_dir='/content/drive/My Drive/Colab Notebooks/validation'
no_train_samples=1306
no_validation_samples=388
epochs=40           #epochs->
batch_size=20       #batch_size->

                                                        #Now we determine channel ordering. Keras supports "channels_last"  (i.e. TensorFlow) and "channels_first"  
                                                        #(i.e. Theano) ordering.Next 4 lines allow our model to support either type of backend.
                                                        
if K.image_data_format()=='channel_first':
    input_shape= (3,img_width,img_height)
#    chanDim=1
else:
    input_shape= (img_width,img_height,3)
#   chanDim=-1

                                                        #Our image is in RGB color space,hence depth of the image is 3,if the image would have been grayscale the image
                                                        #depth would have been 1.  
                                                        #We will be augmenting our data with ImageDataGenerator . Data augmentation is almost always recommended and leads to models that generalize better. 
                                                        #Data augmentation involves adding applying random rotations, shifts, shears, and scaling to existing training data.
                                                        #We won’t see a bunch of new .png and .jpg files — it is done on the fly as the script executes.
train_datagen=ImageDataGenerator(
        rescale=1/255.0,                                #scale the raw pixel intensities from [0,255] to [0,1]->preprocessing step i.e normalization
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

test_datagen=ImageDataGenerator(rescale=1/255)

train_generator=train_datagen.flow_from_directory(  
        train_data_dir,
        target_size=(img_width,img_height),
        batch_size=batch_size,
        class_mode='binary'
        )

validation_genarator=test_datagen.flow_from_directory(
        validation_data_dir,
        target_size=(img_width,img_height),
        batch_size=batch_size,
        class_mode='binary'
        )

model=Sequential()                                      #Initialising the model as Sequential model
model.add(Conv2D(32,(3,3),input_shape=input_shape))     #our first conv layer has 32 filters of size 3*3
model.add(Activation('relu'))                           #Relu(Rectified Linear Unit) activation function has been used
#model.add(BatchNormalization(axis=chanDim))            #Batch Normalization is used to normalize the activations of a given input volume before passing it to the next layer in the network.
                                                        #It has been proven to be very effective at reducing the number of epochs required to train a CNN as well
                                                        #as stabilizing training itself.
model.add(MaxPooling2D(pool_size=(2,2)))                #POOL layers have a primary function of progressively reducing the spatial size (i.e. width and height) of the input volume to a layer.

model.summary()

model.add(Conv2D(32,(3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64,(3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))                                 #Dropout->the process of disconnecting random neurons between layers. This process is proven to reduce overfitting, increase accuracy, and allow our network to 
                                                        #generalize better for unfamiliar images. As denoted by the parameter, 50% of the node connections are randomly disconnected (dropped out) between layers during each training iteration.
model.add(Dense(1))
model.add(Activation('sigmoid'))

model.summary()

#compiling the architecture
model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy'])
#categorical_crossentropy will be used if it there is more than 2 class for classification
#optimizer can also be stochastic gradient descent SGD

#fit the training data i.e train the neural network (most important and time consuming step)
model.fit_generator(
        train_generator,
        steps_per_epoch=no_train_samples,
        epochs=epochs,
        validation_data=validation_genarator,
        validation_steps=no_validation_samples
        )
        
model.save_weights('first_try.h$')
img_pred = image.load_img('/content/drive/My Drive/Colab Notebooks/validation/male/00001006.jpg',target_size=(150,150))
img_pred = image.img_to_array(img_pred)
img_pred = np.expand_dims(img_pred,axis=0)
rslt=model.predict(img_pred)
print(rslt)
if rslt[0][0] > 0.9:
  prediction = "male"
else:
  prediction = "female"
print(prediction)
